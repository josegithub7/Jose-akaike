# -*- coding: utf-8 -*-
"""final NLP Jose.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yg22ipjdo1fRLwf1Tz8F1VNBXCySY_Uw
"""

# natural language processing tasks
!pip install transformers
# For PDF processing
!pip install PyPDF2
# PyTorch as a dependency for the 'transformers' library
!pip install torch

# Import T5 model and tokenizer
from transformers import T5ForConditionalGeneration, T5Tokenizer
# working with deep learning models
import torch
# working with PDF files
import PyPDF2

# tokenization library
!pip install sentencepiece
# specifies the pre-trained T5 model to be used
model_name_or_id = "t5-small"
# Initialize the T5 model by loading the pre-trained model using the specified model_name_or_id.
model = T5ForConditionalGeneration.from_pretrained(model_name_or_id)
# Initialize the T5 tokenizer by loading the pre-trained tokenizer using the same model_name_or_id.
tokenizer = T5Tokenizer.from_pretrained(model_name_or_id)
model_name_or_id = "t5-small"

import os

# Define the actual relative path to your PDF file
relative_path = "sample_data/chapter-2.pdf"

# Get the absolute path to the file
absolute_path = os.path.abspath(relative_path)

# Print the absolute path
print("Absolute Path:", absolute_path)

# Initialize the path to the PDF file to be processed (provide the actual path)
pdf_path = ""
# Define a function to extract text from a PDF file
# Parameters:
# - absolute_path (str): The absolute path to the PDF file to be processed
def extract_text_from_pdf(absolute_path):
  # Initialize an empty string to store the extracted text
    pdf_text = ""
    # Open the PDF file in binary read mode
    pdf_file = open(absolute_path, "rb")
    # Create a PDF reader object
    pdf_reader = PyPDF2.PdfReader(pdf_file)
    # Get the total number of pages in the PDF
    num_pages = len(pdf_reader.pages)
     # Loop through each page of the PDF
    for page_num in range(num_pages):
      # Get the text content of the current page and append it to the result
        page = pdf_reader.pages[page_num]
        pdf_text += page.extract_text()
    # Close the PDF file
    pdf_file.close()
    # Return the extracted text
    return pdf_text
# Call the function to extract text from a PDF file and store the result in pdf_text
# Provide the actual absolute path to the PDF
pdf_text = extract_text_from_pdf(absolute_path)

# Define a function to generate a question from a given prompt using a language model.
# Parameters:
# - prompt (str): The text prompt for generating the question.
# - model: The pre-trained language model.
# - tokenizer: The tokenizer used for encoding and decoding text.
def generate_question(prompt, model, tokenizer):
  # Prepare the input text by formatting it as a question
    input_text = f"question: {prompt}"
    # Encode the input text using the provided tokenizer
    input_ids = tokenizer.encode(input_text, return_tensors="pt")
    # Generate a question from the input using the model
    output = model.generate(input_ids, max_length=50, num_return_sequences=1, num_beams=4)
     # Decode and return the generated question
    generated_question = tokenizer.decode(output[0])
    return generated_question
# Define the prompt that serves as the input for generating the question
prompt = "Summarize the main idea of the following passage:"
# Generate a question based on the prompt using the specified model and tokenizer
generated_question = generate_question(prompt, model, tokenizer)
# Print the generated question to the console
print(generated_question)

# Generate questions and answers
questions_and_answers = []
pdf_text = extract_text_from_pdf(absolute_path)
# Split the PDF text into paragraphs or sections, if needed
# You can split the text based on paragraphs, headings, or any other logical division
# For demonstration, we'll split the text by empty lines
passages = pdf_text.split('\n\n')

# Generate questions for each passage and store them in a list
for passage in passages:
    generated_question = generate_question(passage, model, tokenizer)
    questions_and_answers.append({
        "Passage": passage,
        "Question": generated_question
    })

# Display the generated questions and answers
for qa in questions_and_answers:
    print("Passage:")
    print(qa["Passage"])
    print("\nGenerated Question:")
    print(qa["Question"])
    print("-" * 50)

# Open a file named "generated_questions_and_answers.txt" for writing
with open("generated_questions_and_answers.txt", "w") as file:
   # Iterate through a list of questions and answers
    for qa in questions_and_answers:
      # Write a label indicating the start of the passage
        file.write("Passage:\n")
         # Write the passage text to the file
        file.write(qa["Passage"] + "\n")
          # Write a label indicating the start of the generated question
        file.write("Generated Question:\n")
         # Write the generated question text to the file
        file.write(qa["Question"] + "\n")
        # Write a separator line to distinguish between entries
        file.write("-" * 50 + "\n")

from random import sample

# Function to generate multiple-choice questions with options
def generate_multiple_choice_question(prompt, correct_answer, options, num_options=6):
    incorrect_options = [option for option in options if option != correct_answer]
    random_incorrect_options = sample(incorrect_options, num_options - 1)
    options = random_incorrect_options + [correct_answer]
    question = f"Question: {prompt}\n"
    for i, option in enumerate(options):
        question += f"{chr(65 + i)}. {option}\n"
    return question

# Split the PDF text into smaller sections (e.g., paragraphs)
sections = pdf_text.split("\n\n")  # Split based on empty lines; adjust as needed

questions_and_answers = []

for section in sections:
    generated_question = generate_question(section, model, tokenizer)
    # Replace with the correct answer for the section
    correct_answer = "The British government"
    answer_options = ["French government", "The Spanish monarchy", "The American government", "British rule", "The British"]

    # Generate multiple-choice question
    mcq = generate_multiple_choice_question(generated_question, correct_answer, answer_options)

    questions_and_answers.append({
        "Section": section,
        "Question": mcq
    })

# Display the generated questions and answers
for qa in questions_and_answers:
    print("Section:")
    print(qa["Section"])
    print("\nGenerated Question:")
    print(qa["Question"])
    print("-" * 50)
# Open a file named "generated_questions_and_answers.txt" for writing
with open("generated_multiple_choice_questions_and_answers.txt", "w") as file:
   # Iterate through a list of questions and answers
    for qa in questions_and_answers:
      # Write a label indicating the start of the passage
        file.write("Section:\n")
         # Write the passage text to the file
        file.write(qa["Section"] + "\n")
          # Write a label indicating the start of the generated question
        file.write("Generated Question:\n")
         # Write the generated question text to the file
        file.write(qa["Question"] + "\n")
        # Write a separator line to distinguish between entries
        file.write("-" * 50 + "\n")